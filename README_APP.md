# ADHD Support App

> A React Native mobile application designed to help people with ADHD manage sensory overload and forgetfulness using AI-powered assistance and ambient sound therapy.

## ğŸ¯ Overview

This app provides two core features:

1. **LostToFound** - AI-powered memory assistant that helps you remember where you placed items
2. **SoundSanctuary** - Noise-calming system that plays soothing sounds when ambient noise exceeds your comfort threshold

## âœ¨ Key Features

### LostToFound (Memory Assistant)

- ğŸ¤ **Voice & Text Input**: Record where you place items using natural language
- ğŸ¤– **AI Processing**: Uses LLM (OpenAI, Gemini, or Hugging Face) to understand and extract information
- ğŸ“ **Location Tracking**: Automatically captures GPS coordinates
- ğŸ’¬ **Conversational Queries**: Ask "Where are my keys?" in natural language
- ğŸ—ºï¸ **Google Maps Integration**: Navigate to stored item locations
- ğŸ’¾ **Persistent Storage**: Rolling history of last 30 items (configurable)
- ğŸ”„ **Context-Aware**: Maintains conversation context for intelligent follow-ups

### SoundSanctuary (Noise Calming)

- ğŸ§ **Ambient Noise Monitoring**: Periodically checks environmental noise levels
- ğŸ”Š **Automatic Playback**: Plays soothing sounds when threshold is exceeded
- ğŸŒŠ **Multiple Sound Options**: Rain, ocean waves, forest, white noise
- ğŸšï¸ **Volume Control**: Adjustable playback volume
- ğŸ”‹ **Battery Efficient**: 5-second check intervals instead of continuous monitoring
- âš™ï¸ **Customizable Threshold**: Set your personal noise tolerance level

### Smart Priority Management

- â¸ï¸ **Auto-Pause**: Pause sounds during voice commands
- ğŸ”‰ **Duck Volume**: Lower volume during voice input
- ğŸš« **Ignore Mode**: Continue playback normally
- âš™ï¸ **Configurable**: Choose your preferred behavior in settings

## ğŸ“± Screenshots

*Note: Add screenshots here after testing the app*

## ğŸš€ Quick Start

### Prerequisites

- Node.js 16+
- npm or yarn
- Expo Go app on your phone
- LLM API key (OpenAI, Gemini, or Hugging Face)

### Installation

```bash
# Install dependencies
npm install

# Copy environment template
cp .env.example .env

# Edit .env and add your API key
# Choose one provider: OpenAI, Gemini, or Hugging Face

# Start the app
npm start

# Scan QR code with Expo Go
```

### One-Command Setup (with sample API key)

```bash
# Install and start with demo mode
npm install && echo "OPENAI_API_KEY=demo\nLLM_PROVIDER=openai" > .env && npm start
```

*Note: Demo mode will use local fallback search instead of AI*

## ğŸ“– Documentation

- **[SETUP.md](./SETUP.md)** - Complete setup instructions and configuration
- **[TESTING.md](./TESTING.md)** - Comprehensive testing checklist for all features
- **[WEARABLE_GUIDE.md](./WEARABLE_GUIDE.md)** - Guide for converting to wearable device
- **[API_INTEGRATION.md](./API_INTEGRATION.md)** - LLM API setup for all providers

## ğŸ—‚ï¸ Project Structure

```
adhd-support-app/
â”œâ”€â”€ App.js                          # Main entry point
â”œâ”€â”€ app.json                        # Expo configuration
â”œâ”€â”€ babel.config.js                 # Babel configuration
â”œâ”€â”€ package.json                    # Dependencies
â”œâ”€â”€ .env.example                    # Environment template
â”‚
â”œâ”€â”€ assets/                         # Static assets
â”‚   â”œâ”€â”€ sounds/                     # Soothing sound files
â”‚   â”‚   â”œâ”€â”€ rain.mp3
â”‚   â”‚   â”œâ”€â”€ ocean.mp3
â”‚   â”‚   â”œâ”€â”€ forest.mp3
â”‚   â”‚   â””â”€â”€ white-noise.mp3
â”‚   â””â”€â”€ images/                     # App icons
â”‚
â””â”€â”€ src/
    â”œâ”€â”€ screens/                    # Main screens
    â”‚   â”œâ”€â”€ LostToFoundScreen.js    # Memory assistant UI
    â”‚   â”œâ”€â”€ SoundSanctuaryScreen.js # Noise calming UI
    â”‚   â””â”€â”€ SettingsScreen.js       # Settings UI
    â”‚
    â”œâ”€â”€ context/                    # State management
    â”‚   â””â”€â”€ AppContext.js           # Global app state
    â”‚
    â””â”€â”€ utils/                      # Helper functions
        â””â”€â”€ llmService.js           # LLM API integration
```

## ğŸ”§ Technology Stack

- **Framework**: React Native with Expo SDK 51
- **Navigation**: React Navigation (Bottom Tabs)
- **UI Components**: React Native Paper
- **State Management**: React Context API
- **Storage**: AsyncStorage
- **Audio**: expo-av
- **Location**: expo-location
- **Speech**: expo-speech
- **HTTP Client**: Axios
- **Environment**: react-native-dotenv

## ğŸ”‘ LLM Configuration

### OpenAI (Recommended)

```env
OPENAI_API_KEY=sk-your_key_here
OPENAI_MODEL=gpt-3.5-turbo
LLM_PROVIDER=openai
```

Get key: https://platform.openai.com/api-keys

### Google Gemini (Free Tier)

```env
GEMINI_API_KEY=your_key_here
GEMINI_MODEL=gemini-1.5-flash
LLM_PROVIDER=gemini
```

Get key: https://makersuite.google.com/app/apikey

### Hugging Face (Free Inference)

```env
HUGGINGFACE_API_KEY=your_token_here
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.1
LLM_PROVIDER=huggingface
```

Get token: https://huggingface.co/settings/tokens

## ğŸ“ Usage Examples

### Storing Items

```
User: "I'm leaving my car keys on the kitchen table"
App: "Got it! I've remembered that your car keys are at kitchen table."
```

```
User: "My wallet is in the bedroom drawer"
App: "Got it! I've remembered that your wallet is at bedroom drawer."
```

### Querying Items

```
User: "Where are my car keys?"
App: "Your car keys are at kitchen table (stored on 1/15/2024, 10:30 AM)"
```

```
User: "Where did I put my wallet?"
App: "Your wallet is at bedroom drawer (stored on 1/15/2024, 10:45 AM)"
```

## ğŸ§ª Testing

Run through the comprehensive testing checklist:

```bash
# See TESTING.md for complete test cases
# Quick smoke test:
1. Launch app
2. Store 3 items in LostToFound
3. Query for one of them
4. Go to SoundSanctuary
5. Play a sound
6. Check Settings
```

## ğŸ” Permissions

The app requires:

- **Microphone**: For voice commands and noise monitoring
- **Location**: To remember where items were placed
- **Storage**: To save memories and settings locally

All permissions are requested with clear explanations and can be denied. The app provides text-based fallbacks when voice features are unavailable.

## ğŸ› Troubleshooting

### LLM Not Working
- Check API key is valid
- Verify internet connection
- Check API quota/credits
- App will fallback to local search

### No Audio Playback
- Ensure device volume is up
- Check that sound files exist in assets/sounds/
- Grant microphone permission
- Restart app

### Location Not Saving
- Grant location permission
- Enable location services
- Check GPS signal

### App Crashes
- Clear Expo cache: `expo start -c`
- Reinstall dependencies: `rm -rf node_modules && npm install`
- Check console for errors

## ğŸ¤ Contributing

This is a prototype/demonstration project. For production use:

1. Add proper error boundaries
2. Implement comprehensive testing
3. Add analytics and crash reporting
4. Optimize performance
5. Add accessibility features
6. Implement proper security measures

## ğŸ“„ License

This project is for demonstration purposes.

## ğŸ™ Acknowledgments

- Built for people with ADHD to manage daily challenges
- Inspired by cognitive support tools and ambient sound therapy research
- Uses free-tier LLM APIs for accessibility

## ğŸ“ Support

For issues:
1. Check [SETUP.md](./SETUP.md) troubleshooting section
2. Review [TESTING.md](./TESTING.md) for test cases
3. Consult Expo documentation: https://docs.expo.dev/

## ğŸš§ Future Enhancements

- [ ] Implement real voice recognition (react-native-voice)
- [ ] Add proper audio metering for noise detection
- [ ] Cloud sync across devices
- [ ] User authentication
- [ ] Data export/import
- [ ] Reminders and notifications
- [ ] Apple Watch / Wear OS companion app
- [ ] Offline mode with local ML models
- [ ] Accessibility improvements
- [ ] Multi-language support

## ğŸ“ For Investors

This prototype demonstrates:
- âœ… Working AI integration (multiple providers)
- âœ… Real-time audio monitoring
- âœ… Persistent data storage
- âœ… Cross-platform compatibility (iOS/Android)
- âœ… Production-ready code architecture
- âœ… Clear path to wearable device (see WEARABLE_GUIDE.md)
- âœ… Focused on real user needs (ADHD support)

**Next Steps**: User testing, clinical validation, wearable prototype development

---

**Version**: 1.0.0  
**Last Updated**: January 2024  
**Built with** â¤ï¸ **for the ADHD community**
